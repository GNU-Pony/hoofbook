@node The command line
@chapter The command line
@cindex terminal
@cindex shell

@smallquotation
`In the beginning@dots{} was the command line.' – Neil Stephenson
@end smallquotation

The command line is the most powerful
way to interact with the computer, and
it generally is also the fastest way
to perform actions. But it requires
some knowledge to take full advantage
of it. In this chapter you will learn
how to use the command line in less
basic ways. This chapter only gives an
introductory overview of the command
line and the shell, for more information
you can read @command{info bash}.
If you come to love (or just like)
the command line you should also read
@command{man ssh} and
@command{info screen}.


@menu
* The command line advantage::
* Scripting::
* The structure of commands::
* Redirections and captures::
* Wildcards and patterns::
* Shell script syntax::
* Functions and aliases::
@end menu



@node The command line advantage
@section The command line advantage

@cindex flexibility
@cindex unix-pipes
@cindex pipes
The command line is extremely flexible.
In GNU and all Unix-like systems
command line problems are designed to
to just one thing and be very good at
it. This by itself does not make the
the command line great, rather it makes
it cumbersome to use, but shells in
Unix-like systems — the program that
lets you use the command line — implement
a concept called Unix-pipes. Unix-pipes
is a way to combine programs. This two
designs combine makes the command line
virtually unlimited in its flexibility.

@cindex reliability
@cindex resouce usage
Graphical programs are often immature
and even unstable. In contrast, command
line tools are most often highly
reliable. Not only are graphical
programs not as stable, they are more
resource intensive are often slower
in their output. @footnote{Graphical
text editors are often marginally
faster, but can be much faster when
you paste in a lot of text from
an external clipboard.}

@cindex interaction speed
@cindex speed, interaction
Command line tools are also often
very fast to use, you can perform
most actions by type a dozen or
so keystrokes and you can perform
the one multiple files without
having to repeat the interaction
process. In contrast, many
graphical programs require that
you navigate menus and click
around in long chains. You can
also often find yourself switch
between the mouse and the keyboard
when using text editors and
word processors.

The command line is a very
convenient, accurate and easy
way to describe how to do something.
Most help you will find on the
Internet will use the command
line and almost always do so
by writting a set of commands
in a forum. But there are also
video using the command line
with a narrator that explains
what is going on.

Additionally the command line
is a great learning experience
and have more tools as programmer
often perfer the command line
and find it boring and strenuous
to create graphical user interfaces.

The command line is also a great
diagnostical tool for graphical
programs. All programs, even
graphical ones, can be started
from a terminal. Graphical program
often send more error messages to
the terminal than to dialog boxes,
and you can often fine tune how
to start graphical programs.

@pindex ncurses
But just because a program does
not have a graphical user interface
does not been you have to do
more typing. Some programs,
including basically all text
editors for the terminal, have
graphics inside the terminal,
some even have support for using
the mouse. These programs are
often called ncurses-programs
or curses-programs, named after
the ncurses and curses libraries.
ncurses is a library that makes
it ease to measure the size of
the terminal, use colours and
other formating, configure the
terminal and create graphical
components in the terminal.



@node Scripting
@section Scripting
@cindex scripts
@cindex shell

When you use the command line you
are you are doing using a program
called a shell. A shell is not
just a program for starting other
programs, it is actually an
interpreter for a programming
language of the shell script class
of programming language. A shell
can execute shell script files or
be interactive. In interactive
mode it lets you write in a shell
script language and runs it as
you write in it. This means that
you can create loops, have
conditionals, store values
inside variables, and declare
functions. Most shells use POSIX
@footnote{POSIX is an abbrivation
for Portable Operating System
Interface, ending with an `X' just
because it is Unix-like.}
shell script and extends it.
But a few have their entirely own
syntax.

If you have create a script file
you can either run it by typing
@command{bash your-script} (for
GNU Bash) or by making it
executable by running
@command{chmod a+x your-script}
and type @command{./your-script}
if it is the current directory,
@command{your-script} if it is
@var{PATH} or by its full file
name.

You can also type
@command{. your-script}. Doing
so includes the your script
the current script, if are in
an interative shell it is like
typing the entire content
of that file.

@pindex @command{awk}
As if that is not enough, there
are other scripting languages
such as Perl, Python and AWK
that also use in the shell by
starting their interpreters.
@command{awk} is the most popular
for this as it is most fitted
for this, even though it is
probably the most difficult of
them to learn.



@node The structure of commands
@section The structure of commands

@pindex @command{echo}
@cindex arguments, command line
@cindex command line arguments
A command is composed of an arbitrary
non-zero number of arguments.
@command{echo} is a simple command that
prints arguments verbatim. @command{echo}
is often built in to the shell so that
a new programs does not need to be
executed every time a shell script prints
something.

@opindex @option{-n}, @command{echo}
If you type @command{echo foobar} the
text `foobar' will be printed to the
terminal on one line, if your type
@command{echo -n foobar} most
implementations of @command{echo} will
not print a line ending at the end of
the output yeilding that the next
output starts on the same line, but
some implements will also print `-n'.

@cindex command line argument whitespace
@cindex command line whitespace
If you type @command{echo foo bar} then
`foo bar' will be printed. But if you
insert additinal whitespace, `foo bar'
will still be printed to same why, there
are still just three arguments: `echo',
`foo' and `bar'. To make `foo bar' just
one argument you can put quotes around
it: @command{echo 'foo bar'}, which makes
it just one word, and all whitespace will
be preserved in the output.

@cindex command line special characters
@cindex special characters, command line
Some characters are special characters:
whitespace, quotes, curly, round and
square brackets, `<', `>' `|', `&', `^'
(for ZSH, and sometimes for other shells),
`$', `?', `*', `~', `\', `#', `;', `!'
and grave accent (`) (for some shells,
for example GNU Bash) and depending on
surrounding characters `.',  `,' and `-'.
Special characters can be used in verbatim
form by putting them inside single quotes
as in the previous paragraph, or by
putting a backslash (\), this is called
escaping, directly before it. Double
quotes will allow special characters
but whitespace will be included in
verbatim form. A single-quotation mark
cannot be included inside single quotes,
as special character are ignored, indead
you will have to temporarly close the
quote and add an escaped single-quotation
mark ('like'\''this'). Unescaped hashes
(#) outside quotes are comments, everything
on the same line after it, include the
hash itself, is ignored.

@cindex command line options
@cindex options, command line
@cindex command line flags
@cindex flags, command line
Revisiting @command{echo -n}.
Commands can have directives on
how it should behave. Arguments
starting with a dash (and in some
cases pluses) almost always changes
the behaviour of the command, these
are called options. Simple options
such as @option{-n} for
@command{echo} are called flags.
More complex options have associated
values. These values are actually
also called arguments. The associated
value directly follows the option.
Consider the command @command{date}.
It prints the current date and time,
for example:

@example
$ date   # The dollar sign indicates that you are typing the line
Sun  1 Dec 09:03:20 CET 2013
@end example

If you instead what the date of
yesterday (but with the same time)
you can add the option @option{-d}
with the associated value `yesterday':

@example
$ date -d yesterday
Sat 30 Nov 09:03:20 CET 2013
@end example

Exactly how you can combine options
and their associated value depends
on the command, but normally you
can put them in the same argument:

@example
$ date -dyesterday
Sat 30 Nov 09:03:20 CET 2013
@end example

Recall flags, @command{date -u}
prints the date and time but in
Coordinated Universal Time (UTC):

@example
$ date -u
Sat 30 Nov 08:03:20 UTC 2013
@end example

Flags can be combined in the
same argument and can optionally
be combined with a options that
has a value at the end:

@example
$ date -udyesterday
Sat 30 Nov 08:03:20 UTC 2013

$ date -ud yesterday
Sat 30 Nov 08:03:20 UTC 2013

$ date -duyesterday  # works, but the value is incorrect
date: invalid date ‘uyesterday’

$ date -du yesterday  # not what you meant
date: the argument ‘yesterday’ lacks a leading '+';
when using an option to specify date(s), any non-option
argument must be a format string beginning with '+'
Try 'date --help' for more information.
@end example

Options, including flags, like
these — those starting with a
single dash (or plus) — are called
short options and exists in most
programs and is a convension from
Unix. GNU with is a Unix-like system
improved on this by adding long
options, these are easier to remember
and much easier to understand.
Long options starts with two dashes
(or two pluses), must programs
implements long option alternatives
to short options, but some programs
do not even have short options for
some options:

@example
$ date --utc --date yesterday
Sat 30 Nov 08:03:20 UTC 2013
@end example

Long options cannot be combined,
and their associated values must
either be in there own arguments
or combined using an equals sign:

@example
$ date --utc --date=yesterday
Sat 30 Nov 08:03:20 UTC 2013
@end example

Some options have an associated
value that is options. Consider the
source control management system
Git, it use GNU Privacy Guard (GPG;
GnuPG) to digitally sign commits:

@example
git commit -S
git commit --gpg-sign
@end example

Both signs the commit it creates
with your default key. If you
want to sign with your GPG key
XXXXXXXX you can type either of:

@example
git commit -SXXXXXXXX
git commit --gpg-sign=XXXXXXXX
@end example

But you cannot type any of:

@example
git commit -S XXXXXXXX
git commit --gpg-sign XXXXXXXX
@end example

@cindex command line verb
@cindex verb, command line
In these examples, @command{commit}
is called a verb, it specifies
what subsystem in Git to call, and
must be placed before all options.

@opindex @option{--}
@opindex @option{++}
There is also a special short
option supported by most programs:
@option{--}. It stops all arguments
after it to be parsed as options,
it is often used, especially in
scripts, to make sure that filenames
are not parsed as options if they
start with dash. Many GNU/Pony
programs use a library called
`argparser'. Programs using
argparser and few other programs
supports the short option
@option{++} which prevents only
the next argument to be parsed as
an option. However, @option{--}
and @option{++},
can seldomly be combined with
other short options.

@pindex @command{find}
A few programs, such as @command{find},
uses alternative options. These are
long options that only have one dash.
The reason for this complication is
that long options were never used in
Unix, and GNU needed to be backwards
compatible with Unix. @command{find},
list all files in the current directory
and all subdirectories. But it can also
filter its output; if you want to list
all files named @file{my-document} you run
@command{find -name my-document}.


@node Redirections and captures
@section Redirections and captures
@cindex command line redirections
@cindex redirections, command line
@cindex command line captures
@cindex captures, command line

@pindex @command{grep}
@cindex unix-pipes
@cindex command line pipes
@cindex pipes, command line
@cindex pipelines
What makes to the command line so
powerful is the ability to combine
programs. The output of a program
can be the input of another.
For example, assume that you
have not learn @command{find -name}
but you know the very basics of
@command{find} and @command{grep};
@command{find} will list files
and @command{grep} will filter
them. If you type
@command{find | grep my-document}
then all files inside the current
directory and all subdirectories contain
@file{my-document} in their file name
(including directory) will be listed.

@pindex @command{tee}
You can also redirect the output
to a file, or take input from a
file. If you run
@command{find | grep my-document > result}.
The file @file{result} will be
created, or emptied if it already
exists, and filled with the output
of @command{find | grep my-document},
but no output will be printed to
the terminal. If want to print to
the terminal as well, you can use
the command @command{tee}:

@example
find | grep my-document | tee result
@end example

@cindex @file{/dev/null}
Saving to a file can also be used
to suppress the output. There is
a special pseudo-device that output
can be printed to and the output
will be not be printed or saved
any where: @file{/dev/null}.

@command{find} will print error
messages if, for example, you do
not have access permission to
a subdirectory. To suppress this
you can redirect is standard error
channel (stderr) to @file{/dev/null}:

@example
find 2> /dev/null | grep my-document > result
@end example

@code{>} redirects the standard output
channel (stdout) to a file while, @code{2>}
does the same but for standard error.

Put perhaps you do not want to remove
the content of the existing output file.
You can append the output to a file by
using @code{>>} instead of @code{>}
(and @code{2>>} instead of @code{2>}):

@example
find | grep my-document       >  result
find | grep my-other-document >> result
@end example

In some scripts you will find @code{>|}.
It does the same thing as @code{>}, except
that @code{>} will fail if the output file
already exists if the shell is configured
to not override existing files.

Now, inside that you have a directory
with a huge about of files in it and its
subdirectories. Running @command{find}
will take a long time. If you want to
use @command{grep} many times, you
can store the output of @command{find}
and use it many times as input for
@command{grep}:

@example
find > files
grep my-document          < files
grep my-other-document    < files
grep another-document     < files
grep yet-another-document < files
@end example

But perhaps you to store the errors from
@command{find} to @file{files} as well:

@example
find > files 2>&1
@end example

This firsts redirects stdout to
@file{files}, than redirects stderr
to stdout which is now @file{files}.

But wait there is more! You can
capture the output of commands.
The command @command{date +%A}
prints the current weekday:

@example
$ date +%A
Sunday
$ echo "It is $(date +%A) today."
It is Sunday today.
@end example

Some shells, for example GNU Bash,
have a shorthand for this:

@example
$ echo "It is `date +%A` today."
It is Sunday today.
@end example



@node Wildcards and patterns
@section Wildcards and patterns

Wildcards and patterns described
in these section, as well as those
skipped in this section, cannot be
used inside quotes.

@pindex @command{rm}
@cindex swap files
@cindex backup files
When you edit files, backup files
called swap files are created.
These files are named like the
file your are editing but with
an appending tilde (~).
If you want to remove all such
files from a directory use can
use the command @command{rm}
an the utilise the wildcard *.
If you run @command{rm *~} will
files ending with a tilde but
not starting with a dot are
removed. If you want to remove
all such files except those
starting with a dot you can
run @command{rm .*~}. Be aware
that @command{rm *} removes
all files in the current
directory that are not hidden.

If you instead want to remove
files with just one character
in its name, you can run
@command{rm ?}. @code{?} is
a wildcard for any one character,
@code{*} is a wildcard for
anything it can even be matched
to correspond to zero characters.

If @command{*} and @command{?}
cannot be expanded to match any
existing file, those symbols
are instead used verbatim.

Cruly brackets can be used to
reduce the typing. For example,
if you run @command{echo @{a..h@}}
the output will be:

@example
a b c d e f g h
@end example

If you run @command{echo @{8..14@}}
the output will be:

@example
8 9 10 11 12 13 14
@end example

But you can use it between text:

@example
$ echo a@{1..4@}c
a1c a2c a3c a4c
@end example

Similarily you can specify what
it iterates explicitly:

@example
$ echo @{A,B,C@}=@{X,Y,Z@}
A=X A=Y A=Z B=X B=Y B=Z C=X C=Y C=Z
@end example



@node Shell script syntax
@section Shell script syntax

Many small programs and programs
that uses a lot of system calls
are written in shell script. You
are likely to use it your self,
if not just a lite in an
interactive shell just to safe
time.

The most fundamental control is
to only do the next action if the
the last action was successful.
For example, if you want to
create a directory named
@file{my-dir} and move into it
if you where successful in creating
it (a prerequisite for that is
that the directory did not
already exist) you can run
@command{mkdir my-dir && cd my-dir}.
Conversally, you can do the
next action only if the last
failed:
@command{mkdir my-dir || cd my-dir}.
This will create the directory
but only move into it if it was
not create, which would probably
be because it already existed.
If you instead what to move into
it and create if neccessay you
can run:

@example
cd my-dir || mkdir my-dir && cd my-dir
@end example

To be honest, @command{mkdir -p}
could be used as it will create
create all needed directories and
be successful even if the end point
directory exists.

@code{||} have higher precedence
than @code{&&}, so this means
that it will first try
@command{cd my-dir} and then
@command{mkdir my-dir && cd my-dir}.
If you instead run
@command{mkdir my-dir && cd my-dir || cd my-dir},
then
@command{mkdir my-dir && cd my-dir} will
be tried first.

If you need @code{&&} to have
precedence over @code{||} you
can use curly brackets:

@example
@{mkdir my-dir && mkdir my-dir/subdir && cd my-dir/subdir@} || cd my-dir
@end example

This will create @file{my-dir/subdir}
and move into it, but on failure try to
move into @file{my-dir} which may or may
not have been created.

You can use round brackets inside of
curly brackets, but it has another
effect. Round brackets creates a
subshell which means that
@command{cd my-dir/subdir} will
be executed in another shell and
therefore have no effect.

@cindex if-statement, shell
@cindex shell, if-statement
This because a bit unreadable for
larger scripts. If-statements
can be used to add some structure:

@example
if mkdir my-dir && mkdir my-dir/subdir; then
    cd my-dir/subdir
else
    cd my-dir
fi
@end example

In this example you see the special
character `;', it is used to write
multiple commands on the same line.

Alternative, you can write:

@example
mkdir my-dir && mkdir my-dir/subdir
if [ $? = 0 ] then
    cd my-dir/subdir
else
    cd my-dir
fi
@end example

@code{$?} expands to the exit value
of the last executed command. It is
an integer between 0 and 255, inclusively.
A program should return the exit value
zero if and only if it was successful.

@cindex foor-loop, shell
@cindex shell, foor-loop
Another common flow control is the
for-loop. The command @command{echo}
prints all arguments on the same line.
If you want to print on multiple lines
you need to invoke @command{echo} once
for every line. A fast wait to do
this is by using the for-loop:

@example
for text in alpha beta gamma; do
  echo "$@{text@}"
done
@end example

This will print:
@example
alpha
beta
gamma
@end example

@cindex here-document
@pindex @command{cat}
Another why to do this is to use
@command{cat}, which is a command
that prints the content of a file,
and a  construct called
here-documents. Here-documents
declares files inline in the a
script file:

@example
cat <<EOF
alpha
beta
gamma
EOF
@end example

Here-documents can include
the @code{$()} construct.

@cindex here-string
A similar construct, that
is available in GNU Bash,
but not plain POSIX shell,
is here-strings:

@example
$ variable="your very long text"
$ sed s/long/LONG/g <<<"$@{variable@}"
your very LONG text
@end example



@node Functions and aliases
@section Functions and aliases
@cindex shell functions
@cindex function, shell
@cindex alias, shell
@cindex shell aliases

Functions and aliases are two
constructs you will find your
self using when customising your
shell to become more productive.

Aliases are the simpler of the
two. Assume that your running
make files a lot, two aliases
could be very useful to have:

@example
alias m="make -j"
alias mm="make -j -B"
@end example

@pindex @command{make}
@opindex @option{-j}, @command{make}
@opindex @option{-B}, @command{make}
With these to lines in your
@file{~/.bashrc} you can run
@command{m} instead of
@command{make} to build
thing, and you can still
defined variables and specify
what to build. And running
@command{mm} would force files
to be rebuild even if the
timestamp says it is not needed.
Additionally it will use all
your CPU:s and not just one
(the @option{-j} option.)

Functions on the other hand
can be used to do very complex
things. But to keep it simple,
you could define

@example
function i
@{
    info "$@@" invoking
@}
@end example

in your @file{~/.bashrc}. This
will allow to type
@command{i ponysay} instead of
@command{info ponysay invoking}
and @command{i coreutils cp}
instead of
@command{info coreutils cp invoking}.

